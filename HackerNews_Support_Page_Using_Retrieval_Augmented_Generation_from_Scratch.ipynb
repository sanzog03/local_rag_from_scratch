{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbEJmXIlqdNr"
      },
      "source": [
        "# Data preparation/Chunking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CpHd5jG5qdNs",
        "outputId": "bad25379-6db7-4540-f7d8-35f8c9edc71b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "faq.json\n"
          ]
        }
      ],
      "source": [
        "!ls data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UIXWgjxxqdNs"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/sthapa/Devs/rag/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
            "  warnings.warn(\n",
            "/Users/sthapa/Devs/rag/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import spacy\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Chunking using: spacy and en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3_jekn5iqdNt"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def process_file(file_path):\n",
        "    with open(file_path) as f:\n",
        "        data = json.load(f)\n",
        "        content = data[\"content\"]\n",
        "        url = data[\"url\"]\n",
        "        doc = nlp(content)\n",
        "\n",
        "        return [{\"text\": sent.text, \"url\": url} for sent in doc.sents]\n",
        "\n",
        "chunks = [\n",
        "    chunk\n",
        "    for file in os.listdir(\"data\")\n",
        "    for chunk in process_file(os.path.join(\"data\", file))\n",
        "]\n",
        "\n",
        "chunks = [{\"id\": i, **chunk} for i, chunk in enumerate(chunks)]\n",
        "\n",
        "with open(\"chunks.json\", \"w\") as f:\n",
        "    json.dump(chunks, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juLmch1vqdNt"
      },
      "source": [
        "# Vector store"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### vector embedding using: all_mpnet_base_v2 sentence_transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PIyJV8q6qdNt"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batches: 100%|██████████| 4/4 [00:02<00:00,  1.48it/s]\n"
          ]
        }
      ],
      "source": [
        "sentences = [chunk[\"text\"] for chunk in chunks]\n",
        "\n",
        "model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
        "\n",
        "embeddings = model.encode(sentences, show_progress_bar=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.09477425, -0.01864169,  0.00911164, ..., -0.04637649,\n",
              "         0.00228056,  0.01923566],\n",
              "       [ 0.03039058, -0.03222821, -0.03873111, ..., -0.0035764 ,\n",
              "         0.00579478, -0.0339357 ],\n",
              "       [ 0.05490492, -0.06632555,  0.0165215 , ..., -0.02763968,\n",
              "        -0.00135091, -0.00359141],\n",
              "       ...,\n",
              "       [ 0.02805713, -0.06807668, -0.02322498, ..., -0.0072787 ,\n",
              "        -0.00197908,  0.00630819],\n",
              "       [-0.0140816 ,  0.02815344,  0.00403775, ...,  0.03194111,\n",
              "        -0.01472967,  0.02749774],\n",
              "       [ 0.01043997,  0.01733964, -0.02638827, ..., -0.0227873 ,\n",
              "        -0.03920399, -0.04961954]], dtype=float32)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "q-G4xA4zqdNt"
      },
      "outputs": [],
      "source": [
        "faiss_index = faiss.IndexFlatIP(model.get_sentence_embedding_dimension())\n",
        "faiss_index.add(embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7ukxotUqdNt"
      },
      "source": [
        "# Retrieval/Prompt preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ItqK_PNQqdNt"
      },
      "outputs": [],
      "source": [
        "base_prompt = \"\"\"You are an AI assistant. Your task is to understand the user question, and provide an answer using the provided contexts. Every answer you generate should have citations in this pattern  \"Answer [position].\", for example: \"Earth is round [1][2].,\" if it's relevant.\n",
        "\n",
        "Your answers are correct, high-quality, and written by an domain expert. If the provided context does not contain the answer, simply state, \"The provided contexts does not have the answer.\"\n",
        "\n",
        "User question: {}\n",
        "\n",
        "Contexts:\n",
        "{}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XZoA6CBhqdNt"
      },
      "outputs": [],
      "source": [
        "k = 50\n",
        "question = \"Why HackerNews is so popular?\"\n",
        "\n",
        "query_embedding = model.encode([question])\n",
        "distances, indices = faiss_index.search(query_embedding, k)\n",
        "\n",
        "context = \"\\n\".join([f\"{i}. {sentences[index]}\" for i, index in enumerate(indices[0])])\n",
        "prompt = f\"{base_prompt.format(question, context)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0. Hacker News FAQ\n",
            "\n",
            "Are there rules about submissions and comments?https://news.ycombinator.com/newsguidelines.html\n",
            "How are stories ranked?\n",
            "\n",
            "1. HN gives three features to YC: job ads (see above) and startup launches get placed on the front page, and YC founder names are displayed to other YC alumni in orange.\n",
            "\n",
            "2. It's a way to help you prevent yourself from spending too much time on HN.\n",
            "3. Users should vote for a story because they personally find it intellectually interesting, not because someone has content to promote.\n",
            "4. We don't want anyone to get in trouble from anything they posted to HN.\n",
            "5. Why is A ranked below B even though A has more points and is newer?\n",
            "\n",
            "6. These appear on the front page, but are not stories: they have no vote arrows, points, or comments.\n",
            "7. Other factors affecting rank include user flags, anti-abuse software, software which demotes overheated discussions, account or site weighting, and moderator action.\n",
            "\n",
            "8. http://news.ycombinator.com/formatdoc\n",
            "\n",
            "9. Some votes are dropped by anti-abuse software.\n",
            "\n",
            "10. Roughly, the number of upvotes on their posts minus the number of downvotes.\n",
            "11. If you request many pages quickly, your IP address might get banned.\n",
            "12. The good will of the community is worth more than any story.\n",
            "\n",
            "13. Others still see it.\n",
            "\n",
            "14. But please don't post complaints about paywalls.\n",
            "15. The basic algorithm divides points by a power of the time since a story was submitted.\n",
            "16. It's ok to post stories from sites with paywalls that have workarounds.\n",
            "\n",
            "17. Only one is on the front page at a time.\n",
            "18. See \"How are stories ranked?\" above.\n",
            "\n",
            "19. How can I unban it?\n",
            "\n",
            "20. Another kind of job ad is reserved for YC-funded startups.\n",
            "21. This prevents a race to post it first.\n",
            "\n",
            "22. Click on its timestamp to go to its page, then click 'vouch' at the top.\n",
            "23. Are paywalls ok?\n",
            "\n",
            "24. Are negative stories about YC suppressed on HN?\n",
            "No, we moderate less, not more, when YC or a YC startup is the topic.\n",
            "25. It gives you time to edit your comments before they appear to others.\n",
            "26. Comments in threads are ranked the same way.\n",
            "\n",
            "27. Otherwise we bury reposts as duplicates.\n",
            "\n",
            "28. If you turn it on you'll only be allowed to visit the site for maxvisit minutes at a time, with gaps of minaway minutes in between.\n",
            "29. Show HN is for sharing your personal work and has special rules.\n",
            "\n",
            "30. It's also not in your interest: HN readers are sensitive to this and will detect it, flag it, and use unkind words like 'spam'.\n",
            "\n",
            "31. How is a user's karma calculated?\n",
            "\n",
            "32. What do green usernames mean?\n",
            "\n",
            "33. Users flagged the post as breaking the guidelines or otherwise not belonging on HN.\n",
            "\n",
            "34. Are reposts ok?\n",
            "If a story has not had significant attention in the last year or so, a small number of reposts is ok.\n",
            "35. What's the relationship between YC and HN?\n",
            "Y Combinator owns and funds HN.\n",
            "36. My IP address seems to be banned.\n",
            "37. They remove a submission from your personal view.\n",
            "38. Most job ads are welcome there.\n",
            "39. In my profile, what is noprocrast?\n",
            "\n",
            "40. Please don't post job ads as submissions to HN.\n",
            "\n",
            "41. In my profile, what is delay?\n",
            "\n",
            "42. This is to prevent people from submitting a link with their comments in a privileged position at the top of the page.\n",
            "43. Only an account called whoishiring is allowed to submit the thread itself.\n",
            "44. Email hn@ycombinator.com\n",
            "45. How do I submit a poll?\n",
            "http://news.ycombinator.com/newpoll\n",
            "How do I make a link in a text submission?\n",
            "\n",
            "46. Green indicates a new account.\n",
            "\n",
            "47. A regular \"Who Is Hiring?\" thread appears on the first weekday of each month (or Jan 2).\n",
            "48. Those are off topic.\n",
            "49. However, we care about protecting individual users and take care of privacy requests every day, so if we can help, please email hn@ycombinator.com.\n",
            "--------------------------------\n",
            "You are an AI assistant. Your task is to understand the user question, and provide an answer using the provided contexts. Every answer you generate should have citations in this pattern  \"Answer [position].\", for example: \"Earth is round [1][2].,\" if it's relevant.\n",
            "\n",
            "Your answers are correct, high-quality, and written by an domain expert. If the provided context does not contain the answer, simply state, \"The provided contexts does not have the answer.\"\n",
            "\n",
            "User question: Why HackerNews is so popular?\n",
            "\n",
            "Contexts:\n",
            "0. Hacker News FAQ\n",
            "\n",
            "Are there rules about submissions and comments?https://news.ycombinator.com/newsguidelines.html\n",
            "How are stories ranked?\n",
            "\n",
            "1. HN gives three features to YC: job ads (see above) and startup launches get placed on the front page, and YC founder names are displayed to other YC alumni in orange.\n",
            "\n",
            "2. It's a way to help you prevent yourself from spending too much time on HN.\n",
            "3. Users should vote for a story because they personally find it intellectually interesting, not because someone has content to promote.\n",
            "4. We don't want anyone to get in trouble from anything they posted to HN.\n",
            "5. Why is A ranked below B even though A has more points and is newer?\n",
            "\n",
            "6. These appear on the front page, but are not stories: they have no vote arrows, points, or comments.\n",
            "7. Other factors affecting rank include user flags, anti-abuse software, software which demotes overheated discussions, account or site weighting, and moderator action.\n",
            "\n",
            "8. http://news.ycombinator.com/formatdoc\n",
            "\n",
            "9. Some votes are dropped by anti-abuse software.\n",
            "\n",
            "10. Roughly, the number of upvotes on their posts minus the number of downvotes.\n",
            "11. If you request many pages quickly, your IP address might get banned.\n",
            "12. The good will of the community is worth more than any story.\n",
            "\n",
            "13. Others still see it.\n",
            "\n",
            "14. But please don't post complaints about paywalls.\n",
            "15. The basic algorithm divides points by a power of the time since a story was submitted.\n",
            "16. It's ok to post stories from sites with paywalls that have workarounds.\n",
            "\n",
            "17. Only one is on the front page at a time.\n",
            "18. See \"How are stories ranked?\" above.\n",
            "\n",
            "19. How can I unban it?\n",
            "\n",
            "20. Another kind of job ad is reserved for YC-funded startups.\n",
            "21. This prevents a race to post it first.\n",
            "\n",
            "22. Click on its timestamp to go to its page, then click 'vouch' at the top.\n",
            "23. Are paywalls ok?\n",
            "\n",
            "24. Are negative stories about YC suppressed on HN?\n",
            "No, we moderate less, not more, when YC or a YC startup is the topic.\n",
            "25. It gives you time to edit your comments before they appear to others.\n",
            "26. Comments in threads are ranked the same way.\n",
            "\n",
            "27. Otherwise we bury reposts as duplicates.\n",
            "\n",
            "28. If you turn it on you'll only be allowed to visit the site for maxvisit minutes at a time, with gaps of minaway minutes in between.\n",
            "29. Show HN is for sharing your personal work and has special rules.\n",
            "\n",
            "30. It's also not in your interest: HN readers are sensitive to this and will detect it, flag it, and use unkind words like 'spam'.\n",
            "\n",
            "31. How is a user's karma calculated?\n",
            "\n",
            "32. What do green usernames mean?\n",
            "\n",
            "33. Users flagged the post as breaking the guidelines or otherwise not belonging on HN.\n",
            "\n",
            "34. Are reposts ok?\n",
            "If a story has not had significant attention in the last year or so, a small number of reposts is ok.\n",
            "35. What's the relationship between YC and HN?\n",
            "Y Combinator owns and funds HN.\n",
            "36. My IP address seems to be banned.\n",
            "37. They remove a submission from your personal view.\n",
            "38. Most job ads are welcome there.\n",
            "39. In my profile, what is noprocrast?\n",
            "\n",
            "40. Please don't post job ads as submissions to HN.\n",
            "\n",
            "41. In my profile, what is delay?\n",
            "\n",
            "42. This is to prevent people from submitting a link with their comments in a privileged position at the top of the page.\n",
            "43. Only an account called whoishiring is allowed to submit the thread itself.\n",
            "44. Email hn@ycombinator.com\n",
            "45. How do I submit a poll?\n",
            "http://news.ycombinator.com/newpoll\n",
            "How do I make a link in a text submission?\n",
            "\n",
            "46. Green indicates a new account.\n",
            "\n",
            "47. A regular \"Who Is Hiring?\" thread appears on the first weekday of each month (or Jan 2).\n",
            "48. Those are off topic.\n",
            "49. However, we care about protecting individual users and take care of privacy requests every day, so if we can help, please email hn@ycombinator.com.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(context)\n",
        "print(\"--------------------------------\")\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSAzTWesqdNt"
      },
      "source": [
        "# Answer Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "aCDuV2nCqdNt"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'OpenAI' from 'openai' (/Users/sthapa/Devs/rag/.venv/lib/python3.9/site-packages/openai/__init__.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mopenai\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[1;32m      4\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI(\n\u001b[1;32m      5\u001b[0m     base_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://localhost:11434/v1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msk-deepseek-dummy-key\u001b[39m\u001b[38;5;124m\"\u001b[39m,    \n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'OpenAI' from 'openai' (/Users/sthapa/Devs/rag/.venv/lib/python3.9/site-packages/openai/__init__.py)"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    base_url=\"http://localhost:11434/v1\",\n",
        "    api_key = \"sk-deepseek-dummy-key\",    \n",
        ")\n",
        "\n",
        "try:\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"deepseek-r1:8b\",\n",
        "        temperature=0.7,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful and informative assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    print(response.choices[0].message.content)\n",
        "except openai.OpenAIError as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "    print(\"\\nPlease ensure your Ollama server is running and the model is downloaded.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check OPEN AI using Deepseek R1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<think>\n",
            "Okay, so I'm trying to understand what lazy evaluation is in programming. I've heard the term before, maybe in my studies or online articles, but I'm not entirely sure about its meaning. Let me try to break it down step by step.\n",
            "\n",
            "First, I know that evaluation in programming usually refers to how expressions are processed and values are determined. Lazy evaluation must be a specific way of handling this. Maybe it's related to when something is evaluated or computed only when needed instead of upfront. \n",
            "\n",
            "I remember hearing about lazy loading in databases, where certain data isn't fetched until it's actually accessed. Could that be similar? So perhaps in programming, lazy evaluation means that a value or computation is done only when it's required, not beforehand. That would save resources by avoiding unnecessary work unless it's necessary.\n",
            "\n",
            "Wait, so if I have a function that needs some data, and instead of loading the data right away, I wait until the function is called and then load it then? That makes sense for performance optimization. It ensures that we don't waste time or resources on something that might not be used.\n",
            "\n",
            "But how does this apply in different programming contexts? Maybe in functional programming languages like Haskell or Lisp, which are said to use lazy evaluation extensively. In those languages, functions are evaluated lazily, meaning they're only executed when their results are needed. That could prevent infinite loops or stack overflows because the program doesn't evaluate everything upfront.\n",
            "\n",
            "Let me think about an example. Suppose I have a list of numbers, and I want to process each number in a loop. In a language with eager evaluation, like JavaScript, all elements would be processed immediately when the loop starts. But in a language with lazy evaluation, maybe the loop waits until it's told to process each element as they're accessed.\n",
            "\n",
            "Another point is that in some databases or APIs, queries are executed on demand instead of being run every time. So if I have a web page that fetches data from an API, lazy evaluation would mean the data isn't fetched until the user requests it, which saves bandwidth and processing time.\n",
            "\n",
            "I should also consider how this affects data structures and algorithms. Lazy evaluation can lead to more efficient use of memory because objects are created only when needed. This is especially useful in languages with garbage collection since it reduces the amount of data that might be unused.\n",
            "\n",
            "But are there any downsides? Well, if too much is deferred, it could cause delays or unexpected waits when something is finally accessed. For example, in a game loop, if rendering is lazy, each frame might take longer to render once the data is fetched. So it's all about balance and knowing when to evaluate things lazily versus eagerly.\n",
            "\n",
            "I also wonder how this compares to memoization. Memoization caches results so that they don't need to be recomputed, which is a form of optimization but not exactly the same as lazy evaluation. Maybe they are related in some ways, especially in functional programming where both can help optimize performance by avoiding redundant work.\n",
            "\n",
            "In summary, lazy evaluation seems to be about deferring computations or data fetching until it's necessary. This approach can lead to better performance and efficiency, especially in resource-constrained environments. It's widely used in certain programming languages and patterns to optimize resource usage.\n",
            "</think>\n",
            "\n",
            "Lazy evaluation in programming is a strategy where the evaluation of expressions or computations is deferred until they are actually needed. This approach optimizes resource use by ensuring that computations or data fetching occur only when necessary, rather than upfront. Here's a structured summary of the concept:\n",
            "\n",
            "1. **Definition**: Lazy evaluation means that values or computations are processed only when they are required, not beforehand. This can save resources and avoid unnecessary work.\n",
            "\n",
            "2. **Contexts of Use**:\n",
            "   - **Functional Programming**: Languages like Haskell and Lisp use lazy evaluation, where functions are executed only when their results are needed, preventing issues like infinite loops.\n",
            "   - **Database Management**: Similar to lazy loading in databases, data is fetched or processed only when accessed, conserving bandwidth and processing time.\n",
            "   - **Web Development**: APIs and data fetching can be optimized by deferring requests until they're needed.\n",
            "\n",
            "3. **Examples**:\n",
            "   - In a loop processing a list, elements are accessed only as needed, reducing upfront computation.\n",
            "   - Web pages fetch data from APIs on demand, saving resources.\n",
            "\n",
            "4. **Benefits**:\n",
            "   - **Efficiency**: Reduces resource consumption and avoids unnecessary computations.\n",
            "   - **Memory Management**: Lower memory usage as objects are created only when needed, beneficial in languages with garbage collection.\n",
            "   \n",
            "5. **Considerations**:\n",
            "   - Balancing deferred evaluation to avoid delays or performance issues, especially in real-time applications like gaming.\n",
            "\n",
            "6. **Comparison with Memoization**: While related in optimizing performance, memoization caches results to avoid recomputation, distinct from lazy evaluation's focus on deferring processing.\n",
            "\n",
            "In essence, lazy evaluation enhances efficiency by deferring computations and data fetching until they are needed, making it particularly useful in resource-sensitive environments.\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "# --- New syntax for openai library v1.0.0+ ---\n",
        "# Import the OpenAI client`` class\n",
        "from openai import OpenAI\n",
        "\n",
        "# Create an instance of the OpenAI client.\n",
        "# This client object will handle the API calls.\n",
        "# Set the base_url to the correct HTTP endpoint for Ollama.\n",
        "# Note that it's 'http' not 'https'\n",
        "client = OpenAI(\n",
        "    base_url=\"http://localhost:11434/v1\",\n",
        "    api_key = \"sk-deepseek-dummy-key\",    \n",
        ")\n",
        "\n",
        "# Define a sample prompt for the model.\n",
        "prompt = \"Explain the concept of 'lazy evaluation' in programming.\"\n",
        "\n",
        "try:\n",
        "    # Use the client instance to make the API call with the new syntax.\n",
        "    # The method is now `client.chat.completions.create`.\n",
        "    # The arguments are largely the same.\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"deepseek-r1:8b\",\n",
        "        temperature=0.7,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful and informative assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Access the content from the response object. The syntax for this also changed\n",
        "    # from a dictionary-like access to a more object-oriented one.\n",
        "    print(response.choices[0].message.content)\n",
        "\n",
        "except openai.OpenAIError as e:\n",
        "    # The exception class has changed, but you can still catch it.\n",
        "    print(f\"An error occurred: {e}\")\n",
        "    print(\"\\nPlease ensure your Ollama server is running and the model is downloaded.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
